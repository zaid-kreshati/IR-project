{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2d5369",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ada179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from app.services.evaluation.evaluator import compute_map,compute_recall\n",
    "from app.services.tfidf_service import VectorSpaceModel\n",
    "import os\n",
    "\n",
    "\n",
    "dataset_name1='nano-beir/arguana'\n",
    "dataset_name2='beir/webis-touche2020/v2'\n",
    "dataset_name3='beir/quora/test'\n",
    "\n",
    "datasetname=dataset_name3\n",
    "name=datasetname.replace(\"/\", \"-\").replace(\"\\\\\", \"_\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc7f7d",
   "metadata": {},
   "source": [
    "## Load queries and qrels files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e746ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not datasetname:\n",
    "    raise ValueError(\"datasetname variable is not defined\")\n",
    "\n",
    "qrels_df = pd.read_csv(f\"data/{datasetname}/qrels.tsv\", sep=\"\\t\", names=[\"query_id\", \"doc_id\", \"relevance\"])\n",
    "# print(qrels_df)\n",
    "queries_df = pd.read_csv(f\"data/{datasetname}/queries.tsv\", sep=\"\\t\", names=[\"query_id\", \"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbdc10",
   "metadata": {},
   "source": [
    "# make instance from VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffcbf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Loading TF-IDF vectorizer, matrix, inverted index...\n"
     ]
    }
   ],
   "source": [
    "vsm=VectorSpaceModel(datasetname)\n",
    "vsm.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94186016",
   "metadata": {},
   "source": [
    "## compute MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e6cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_scores = []\n",
    "query_ids = []\n",
    "\n",
    "for _, row in tqdm(queries_df.iterrows(), total=len(queries_df)):\n",
    "    query_id = row[\"query_id\"]\n",
    "    query_text = row[\"text\"]\n",
    "    \n",
    "    # Get top_k docs from your system\n",
    "    search_results = vsm.search_with_inverted_index(query_text, top_k=10000)\n",
    "\n",
    "\n",
    "    # Access the list of result dicts\n",
    "    result_items = search_results[\"results\"]\n",
    "    retrieved_doc_ids = [str(doc[\"doc_id\"]) for doc in result_items]\n",
    "\n",
    "    map_score = compute_map(retrieved_doc_ids, qrels_df, query_id)\n",
    "    print(f\"\\n map_score: {map_score}\")\n",
    "    map_scores.append(map_score)\n",
    "    query_ids.append(query_id)\n",
    "    # print(f\"\\nâœ… Mean Average Precision (MAP): {map_score:.4f}\")\n",
    "    map_df = pd.DataFrame({\n",
    "    \"query_id\": query_ids,\n",
    "    \"map_score\": map_scores\n",
    "})\n",
    "\n",
    "output_dir = os.path.join(\"results\", \"MAP\", \"TF-IDF\", name)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_dir, f\"{name}_map_scores.csv\")\n",
    "try:\n",
    "    map_df.to_csv(output_path, index=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file to {output_path}: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Also print overall MAP\n",
    "overall_map = sum(map_scores) / len(map_scores)\n",
    "print(f\"\\nðŸ“ˆ Overall MAP: {overall_map:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed0053",
   "metadata": {},
   "source": [
    "## RECALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71c010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Searching with inverted index...\n",
      "ðŸ” Loading TF-IDF vectorizer, matrix, inverted index...\n",
      "ðŸ” Building query inverted index...\n",
      "retrieved_doc: 9681\n",
      "recall: 0.0\n",
      "ðŸ” Searching with inverted index...\n",
      "ðŸ” Loading TF-IDF vectorizer, matrix, inverted index...\n",
      "ðŸ” Building query inverted index...\n",
      "retrieved_doc: 1239\n",
      "recall: 0.0\n",
      "ðŸ” Searching with inverted index...\n",
      "ðŸ” Loading TF-IDF vectorizer, matrix, inverted index...\n",
      "ðŸ” Building query inverted index...\n",
      "retrieved_doc: 32426\n",
      "recall: 0.0\n",
      "ðŸ” Searching with inverted index...\n",
      "ðŸ” Loading TF-IDF vectorizer, matrix, inverted index...\n",
      "ðŸ” Building query inverted index...\n",
      "retrieved_doc: 11913\n",
      "recall: 0.0\n",
      "ðŸ” Searching with inverted index...\n",
      "ðŸ” Loading TF-IDF vectorizer, matrix, inverted index...\n",
      "ðŸ” Building query inverted index...\n",
      "retrieved_doc: 5813\n",
      "recall: 0.0\n",
      "ðŸ” Searching with inverted index...\n",
      "ðŸ” Loading TF-IDF vectorizer, matrix, inverted index...\n",
      "ðŸ” Building query inverted index...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m query_text = row[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Get ALL retrieved docs (no top_k cutoff)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m results = \u001b[43mvsm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch_with_inverted_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or async call with await\u001b[39;00m\n\u001b[32m      9\u001b[39m retrieved_doc = results[\u001b[33m\"\u001b[39m\u001b[33mmatched_count\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mretrieved_doc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretrieved_doc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IR-project/app/services/tfidf_service.py:118\u001b[39m, in \u001b[36mVectorSpaceModel.search_with_inverted_index\u001b[39m\u001b[34m(self, query, top_k)\u001b[39m\n\u001b[32m    114\u001b[39m similarities = cosine_similarity(query_vec, sub_matrix).flatten()\n\u001b[32m    115\u001b[39m top_indices = similarities.argsort()[::-\u001b[32m1\u001b[39m][:top_k]\n\u001b[32m    117\u001b[39m matching_docs = [\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mdoc_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.doc_ids[\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmatched_docs\u001b[49m\u001b[43m)\u001b[49m[i]], \u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(similarities[i])}\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_indices \u001b[38;5;28;01mif\u001b[39;00m similarities[i] > \u001b[32m0\u001b[39m\n\u001b[32m    120\u001b[39m ]\n\u001b[32m    121\u001b[39m matching_count = \u001b[38;5;28msum\u001b[39m(\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m similarities \u001b[38;5;28;01mif\u001b[39;00m score > \u001b[32m0\u001b[39m)\n\u001b[32m    123\u001b[39m end_time = time.time()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "recall_scores = []\n",
    "\n",
    "for i, row in queries_df.iterrows():\n",
    "    query_id = str(row[\"query_id\"])\n",
    "    query_text = row[\"text\"]\n",
    "\n",
    "    # Get ALL retrieved docs (no top_k cutoff)\n",
    "    results = vsm.search_with_inverted_index(query_text, top_k=10000)  # or async call with await\n",
    "    retrieved_doc = results[\"matched_count\"]\n",
    "    print(f\"retrieved_doc: {retrieved_doc}\")\n",
    "\n",
    "    recall = compute_recall(retrieved_doc, qrels_df, query_id)\n",
    "    print(f\"recall: {recall}\")\n",
    "    recall_scores.append({\"query_id\": query_id, \"recall\": recall})\n",
    "\n",
    "\n",
    "\n",
    "recall_df = pd.DataFrame(recall_scores)\n",
    "output_dir = f\"results/Recall/TF-IDF\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "recall_df.to_csv(f\"{output_dir}/{name}_recall_scores.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de8cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
