{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2d5369",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ada179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from app.services.evaluator import compute_recall,compute_precision,compute_average_precision,compute_precision_at_k,compute_mrr\n",
    "from app.services.bm25_service import BM25Service\n",
    "import os\n",
    "\n",
    "\n",
    "dataset_name1='nano-beir/arguana'\n",
    "dataset_name2='beir/webis-touche2020/v2'\n",
    "dataset_name3='beir/quora/test'\n",
    "dataset_name4='antique/test'\n",
    "\n",
    "\n",
    "datasetname=dataset_name4\n",
    "name=datasetname.replace(\"/\", \"-\").replace(\"\\\\\", \"_\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc7f7d",
   "metadata": {},
   "source": [
    "## Load queries and qrels files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e746ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not datasetname:\n",
    "    raise ValueError(\"datasetname variable is not defined\")\n",
    "\n",
    "qrels_df = pd.read_csv(f\"data/{name}/qrels.tsv\", sep=\"\\t\", names=[\"query_id\", \"doc_id\", \"relevance\"])\n",
    "# print(qrels_df)\n",
    "queries_df = pd.read_csv(f\"data/{name}/queries.tsv\", sep=\"\\t\", names=[\"query_id\", \"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbdc10",
   "metadata": {},
   "source": [
    "# make instance from VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffcbf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Loading BM25 model for collection: antique-test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'collection': 'antique-test',\n",
       " 'total_documents': 403666,\n",
       " 'sample_doc_id': '2020338_0',\n",
       " 'sample_tokens': ['a',\n",
       "  'small',\n",
       "  'group',\n",
       "  'of',\n",
       "  'politicians',\n",
       "  'believed',\n",
       "  'strongly',\n",
       "  'that',\n",
       "  'the',\n",
       "  'fact'],\n",
       " 'inverted_index_size': 190239}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25=BM25Service(datasetname)\n",
    "bm25.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc435b9b",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57de8cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [10:02<00:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.2915\n",
      "MRR: 0.8696\n",
      "All Recall values: [0.9166666666666666, 0.7666666666666667, 0.6521739130434783, 0.5365853658536586, 0.8387096774193549, 0.5277777777777778, 0.8181818181818182, 0.6896551724137931, 0.6774193548387096, 0.05555555555555555, 0.6216216216216216, 0.782608695652174, 0.8, 0.8709677419354839, 0.7777777777777778, 0.45161290322580644, 0.6956521739130435, 0.5454545454545454, 0.5588235294117647, 0.8, 0.3, 0.7, 0.6756756756756757, 0.8846153846153846, 0.875, 0.7058823529411765, 0.5294117647058824, 0.41379310344827586, 0.4411764705882353, 0.725, 0.4772727272727273, 0.7777777777777778, 0.88, 0.41025641025641024, 0.7586206896551724, 0.7857142857142857, 0.6122448979591837, 0.7333333333333333, 0.5714285714285714, 0.896551724137931, 0.5476190476190477, 0.8333333333333334, 0.9565217391304348, 0.6296296296296297, 0.8333333333333334, 0.8235294117647058, 0.8333333333333334, 0.5142857142857142, 0.6923076923076923, 0.9, 0.7, 0.7096774193548387, 0.25, 0.5365853658536586, 0.6571428571428571, 0.6875, 0.5, 0.8571428571428571, 0.38461538461538464, 0.8076923076923077, 0.5555555555555556, 0.7, 0.875, 0.5862068965517241, 0.28125, 0.8461538461538461, 0.5806451612903226, 0.6785714285714286, 0.36666666666666664, 0.7272727272727273, 0.71875, 0.8181818181818182, 0.8, 1.0, 0.75, 0.7777777777777778, 0.65, 0.7948717948717948, 0.9375, 0.90625, 0.6571428571428571, 0.7941176470588235, 0.7619047619047619, 0.5238095238095238, 0.7560975609756098, 0.8181818181818182, 1.0, 0.7777777777777778, 0.8285714285714286, 0.8, 0.25, 0.3939393939393939, 0.875, 0.6333333333333333, 0.484375, 0.6896551724137931, 0.07142857142857142, 0.9375, 0.75, 0.7647058823529411, 0.3448275862068966, 0.9629629629629629, 0.52, 0.8260869565217391, 0.48333333333333334, 0.76, 0.3125, 0.5833333333333334, 0.627906976744186, 0.9565217391304348, 0.5483870967741935, 0.5555555555555556, 0.43243243243243246, 0.3333333333333333, 0.5, 0.6774193548387096, 0.5555555555555556, 0.7352941176470589, 0.68, 0.4878048780487805, 0.3225806451612903, 0.8888888888888888, 0.84, 0.40350877192982454, 0.5909090909090909, 0.2545454545454545, 0.6744186046511628, 0.7058823529411765, 0.37142857142857144, 0.6666666666666666, 0.5172413793103449, 0.5588235294117647, 0.875, 0.6060606060606061, 0.967741935483871, 0.3333333333333333, 0.0, 0.6046511627906976, 0.2222222222222222, 0.0, 0.9117647058823529, 0.6842105263157895, 0.8205128205128205, 0.6296296296296297, 0.4411764705882353, 0.6136363636363636, 0.24242424242424243, 0.85, 0.7083333333333334, 0.6578947368421053, 0.7, 0.6756756756756757, 0.4791666666666667, 0.78125, 0.5483870967741935, 0.875, 1.0, 0.7333333333333333, 0.40540540540540543, 0.6571428571428571, 0.7380952380952381, 0.7894736842105263, 0.3793103448275862, 0.9523809523809523, 0.696969696969697, 0.6785714285714286, 0.9130434782608695, 0.5263157894736842, 0.5769230769230769, 0.53125, 0.5777777777777777, 0.5128205128205128, 0.6410256410256411, 0.7586206896551724, 0.8974358974358975, 0.6666666666666666, 0.8484848484848485, 0.8235294117647058, 1.0, 0.6666666666666666, 0.4642857142857143, 0.8, 0.7368421052631579, 0.5833333333333334, 0.8518518518518519, 0.5757575757575758, 0.35294117647058826, 0.38461538461538464, 0.42857142857142855, 0.8695652173913043, 0.9705882352941176, 0.8, 0.3333333333333333, 0.9583333333333334, 0.6097560975609756, 0.7894736842105263, 0.5, 0.2702702702702703, 0.725, 0.16666666666666666]\n",
      "All Precision@10 values: [0.2, 0.9, 0.8, 0.3, 0.8, 0.7, 0.7, 0.4, 0.3, 0.1, 0.7, 0.7, 0.2, 0.8, 0.7, 0.2, 0.6, 0.7, 0.3, 0.4, 0.1, 0.6, 0.1, 0.5, 0.5, 0.9, 0.7, 0.6, 0.1, 0.2, 0.3, 1.0, 0.7, 0.4, 0.9, 0.8, 0.4, 0.7, 0.7, 0.9, 0.5, 0.8, 0.9, 0.5, 0.9, 0.9, 1.0, 0.6, 0.5, 0.4, 0.4, 0.3, 0.2, 0.3, 0.7, 0.8, 0.4, 0.8, 0.5, 0.8, 0.5, 0.5, 0.3, 0.3, 0.4, 0.6, 0.4, 0.8, 0.1, 0.5, 0.9, 0.6, 0.6, 0.8, 0.6, 0.8, 0.3, 0.8, 0.9, 0.8, 1.0, 0.7, 0.7, 0.1, 0.9, 0.9, 0.9, 0.5, 0.5, 0.5, 0.6, 0.2, 0.9, 0.9, 0.2, 0.8, 0.1, 0.9, 0.9, 0.8, 0.3, 0.6, 0.1, 1.0, 0.5, 0.4, 0.4, 0.0, 0.4, 0.9, 0.1, 0.6, 0.5, 0.3, 0.2, 0.9, 0.6, 0.8, 0.5, 0.6, 0.2, 0.7, 0.5, 0.7, 0.3, 0.2, 0.5, 0.3, 0.3, 0.9, 0.2, 0.6, 0.7, 0.7, 0.2, 0.2, 0.0, 0.6, 0.2, 0.0, 0.7, 0.5, 0.8, 0.2, 0.2, 0.5, 0.3, 0.6, 1.0, 0.3, 0.8, 0.5, 0.6, 0.7, 1.0, 1.0, 0.9, 0.4, 0.3, 0.6, 0.8, 0.8, 0.2, 0.9, 0.4, 0.2, 1.0, 0.5, 0.9, 0.3, 0.8, 0.5, 0.5, 0.7, 0.8, 0.1, 0.0, 0.6, 0.8, 0.6, 0.4, 0.6, 0.6, 0.8, 0.8, 0.6, 0.1, 0.3, 0.4, 1.0, 0.9, 0.8, 0.3, 0.5, 0.6, 0.6, 0.9, 0.3, 0.9, 0.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_avg_precisions = []\n",
    "all_prec_at_10 = []\n",
    "all_mrr_ranks = []\n",
    "all_recall = []\n",
    "\n",
    "for _, row in tqdm(queries_df.iterrows(), total=len(queries_df)):\n",
    "    query_id = row[\"query_id\"]\n",
    "    query_text = row[\"text\"]\n",
    "\n",
    "    # Use your VSM search function\n",
    "    search_results = bm25.search(query_text,top_k=1000)\n",
    "     # Access the list of result dicts\n",
    "    result_items = search_results[\"results\"]\n",
    "    retrieved_docs = [str(doc[\"doc_id\"]) for doc in result_items]\n",
    "\n",
    "    # Step 2: Convert both retrieved and relevant doc_ids to strings\n",
    "    relevant_docs = set(qrels_df[qrels_df[\"query_id\"] == query_id][\"doc_id\"].astype(str))\n",
    "\n",
    "\n",
    "    # retrieved_docs = [doc[\"doc_id\"] for doc in search_results]\n",
    "\n",
    "    # Compute metrics\n",
    "    avg_precision = compute_average_precision(relevant_docs, retrieved_docs)\n",
    "    prec_at_10 = compute_precision_at_k(relevant_docs, retrieved_docs, k=10)\n",
    "    recall=compute_recall(relevant_docs, retrieved_docs)\n",
    "\n",
    "    # Compute rank of first relevant doc for MRR\n",
    "    rank = 0\n",
    "    for i, doc_id in enumerate(retrieved_docs):\n",
    "        if doc_id in relevant_docs:\n",
    "            rank = i + 1\n",
    "            break\n",
    "\n",
    "    all_avg_precisions.append(avg_precision)\n",
    "    all_prec_at_10.append(prec_at_10)\n",
    "    all_mrr_ranks.append(rank)\n",
    "    all_recall.append(recall)\n",
    "\n",
    "# Final scores\n",
    "map_score = sum(all_avg_precisions) / len(all_avg_precisions)\n",
    "mean_prec_at_10 = sum(all_prec_at_10) / len(all_prec_at_10)\n",
    "mrr_score = compute_mrr(all_mrr_ranks)\n",
    "\n",
    "print(f\"MAP: {map_score:.4f}\")\n",
    "print(f\"MRR: {mrr_score:.4f}\")\n",
    "print(f\"All Recall values: {all_recall}\")\n",
    "print(f\"All Precision@10 values: {all_prec_at_10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5990ae6",
   "metadata": {},
   "source": [
    "## save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b03a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "summary = {\n",
    "    \"Mean Average Precision\": map_score,\n",
    "    \"Mean Reciprocal Rank\": mrr_score\n",
    "}\n",
    "import json\n",
    "\n",
    "output_dir = os.path.join(\"results\", \"BM25\", name)\n",
    "os.makedirs(output_dir)\n",
    "output_path = os.path.join(output_dir,\"evaluation_summary.json\")\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(summary, f)\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'All Recall value': all_recall, 'All Precision@10 values': all_prec_at_10})\n",
    "\n",
    "# Convert string path to Path object\n",
    "output_dir = Path(\"results/BM25/\")/name\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save as TSV\n",
    "df.to_csv(output_dir / 'evaluation.tsv', sep='\\t', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d2fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
